{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lz4\n!pip install mtcnn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from math import sqrt\nfrom numpy import load, asarray, zeros, ones, savez_compressed\nfrom numpy.random import randn, randint\nfrom skimage.transform import resize\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D\nfrom tensorflow.keras.layers import UpSampling2D, AveragePooling2D, LeakyReLU, Layer, Add\nfrom keras.constraints import max_norm\nfrom keras.initializers import RandomNormal\nimport mtcnn\nfrom mtcnn.mtcnn import MTCNN\n\nfrom matplotlib import pyplot\nimport cv2\nimport os\nfrom os import listdir\nfrom PIL import Image\nimport cv2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image(filename):\n\n    image = Image.open(filename)\n    image = image.convert('RGB')\n    pixels = np.array(image)\n    return pixels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef extract_face(model, pixels, required_size=(128, 128)):\n    # detect face in the image\n    faces = model.detect_faces(pixels)\n    if len(faces) == 0:\n        return None\n    \n    # extract details of the face\n    x1, y1, width, height = faces[0]['box']\n    x1, y1 = abs(x1), abs(y1)\n    \n    x2, y2 = x1 + width, y1 + height\n    face_pixels = pixels[y1:y2, x1:x2]\n    image = Image.fromarray(face_pixels)\n    image = image.resize(required_size)\n    face_array = asarray(image)\n    \n    return face_array\n    \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_faces(directory,n_faces):\n    model = MTCNN()\n    faces = list()\n    #print(os.listdir(directory))\n    for filename in os.listdir(directory):\n        #print(filename)\n        #print(os.path.join(directory,filename))\n        pixels = load_image(os.path.join(directory,filename))\n        face = extract_face(model,pixels)\n        if face is None:\n            continue\n        faces.append(face)\n        print(len(faces),face.shape)\n        if(len(faces)>= n_faces):\n            \n            break\n\n\n    return np.array(faces)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load and extract all faces\nfrom numpy import savez_compressed\nimport numpy as np\n# load and extract all faces\ndirectory = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'\nall_faces = load_faces(directory,50000)\nprint('Loaded: ', all_faces.shape)\n\n# save in compressed format\nsavez_compressed('img_align_celeba_128.npz', all_faces)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nclass PixelNormalization(Layer):\n    def __init__(self,**kwargs):\n        super(PixelNormalization,self).__init__(*kwargs)\n\n    def call(self,inputs):\n        values = inputs**2\n        mean_values = tf.reduce_mean(values, axis=-1, keepdims=True)\n        mean_values += 1e-8\n        l2 = tf.sqrt(mean_values)\n        normalized = inputs/l2\n        return normalized\n\n    def compute_output_shape(self, input_shape):\n        return input_shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nclass MinibatchStdev(Layer):\n    def __init__(self, **kwargs):\n        super(MinibatchStdev, self).__init__(**kwargs)\n    \n    def call(self, inputs):\n        mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n        squ_diffs = tf.square(inputs - mean)\n        mean_sq_diff = tf.reduce_mean(squ_diffs, axis=0, keepdims=True)\n        mean_sq_diff += 1e-8  # Fixed: use same variable name\n        stdev = tf.sqrt(mean_sq_diff)  # Fixed: use same variable name\n        mean_pix = tf.reduce_mean(stdev, keepdims=True)\n        shape = tf.shape(inputs)\n        output = tf.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n        combined = tf.concat([inputs, output], axis=-1)\n        return combined\n    \n    def compute_output_shape(self, input_shape):\n        input_shape = list(input_shape)\n        input_shape[-1] += 1\n        return tuple(input_shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nclass WeightedSum(Add):\n    def __init__(self,alpha = 0.0, **kwargs):\n        super(WeightedSum,self).__init__(**kwargs)\n        self.alpha = tf.Variable(initial_value=alpha, trainable=True, dtype=tf.float32, name=\"ws_alpha\")\n\n    def _merge_function(self,inputs):\n        assert(len(inputs)==2)\n        output = ((1.0 - self.alpha)*inputs[0]) + (self.alpha * inputs[1])\n        return output\n\ndef wasserstein_loss(ytrue,ypred):\n    return tf.reduce_mean(ytrue*ypred)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_real_samples(filename):\n    data = load(filename)\n    x = data['arr_0']\n    x = x.astype('float32')\n    x = (x - 127.5)/127.5\n    return x\n\ndef  generate_real_samples(dataset,n_samples):\n    ix = randint(0,dataset.shape[0],n_samples)\n    X = dataset[ix]\n    y = ones((n_samples,1))\n    return X,y\n\ndef generate_latent_points(latent_dim, n_samples):\n    x_input = randn(latent_dim * n_samples)\n    x_input = x_input.reshape(n_samples,latent_dim)\n    return x_input\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\ndef generate_fake_samples(generator,latent_dim,n_samples):\n    x_input = generate_latent_points(latent_dim,n_samples)\n    X = generator.predict(x_input)\n    y = -ones((n_samples, 1))\n    return X,y\n\n\ndef update_fadein(models, step, n_steps):\n    alpha = step / float(n_steps - 1)\n    for model in models:\n        for layer in model.layers:\n            if isinstance(layer, WeightedSum):\n                tf.keras.backend.set_value(layer.alpha, alpha)\n\n\ndef scale_dataset(images,new_shape):\n    images_list  = list()\n    for image in images:\n        new_image = resize(image,new_shape,0)\n        images = images_list.append(new_image)\n    return asarray(images_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# adding a generator block\ndef add_generator_block(old_model):\n    init = RandomNormal(stddev=0.02)\n    const = max_norm(1.0)\n    block_end = old_model.layers[-2].output\n    \n    # upsample, and define new block\n    upsampling = UpSampling2D()(block_end)\n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n    \n    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n    model1 = Model(old_model.input, out_image)\n    out_old = old_model.layers[-1]\n    out_image2 = out_old(upsampling)\n    \n    merged = WeightedSum()([out_image2, out_image])\n    model2 = Model(old_model.input, merged)\n    return [model1, model2]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def define_generator(latent_dim,n_blocks,in_dim=4):\n    init = RandomNormal(stddev = 0.2)\n    const  = max_norm(1.0)\n    model_list = list()\n    in_latent = Input(shape = (latent_dim,))\n    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n    g  = Reshape((in_dim,in_dim,128))(g)\n    \n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n    \n    # conv 3x3\n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n\n    out_image = Conv2D(3,(1,1),kernel_initializer = init , kernel_constraint = const)(g)\n    model = Model(in_latent,out_image)\n    model_list.append([model,model])\n\n    for i in range(1,n_blocks):\n        old_model = model_list[i-1][0]\n        models = add_generator_block(old_model)\n        model_list.append(models)\n\n    return model_list\n\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# adding a discriminator block\ndef add_discriminator_block(old_model, n_input_layers=3):\n    init = RandomNormal(stddev=0.02)\n    const = max_norm(1.0)\n    in_shape = list(old_model.input.shape)\n    \n    # define new input shape as double the size\n    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n    in_image = Input(shape=input_shape)\n    \n    # define new input processing layer\n    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n    d = LeakyReLU(alpha=0.2)(d)\n    \n    # define new block\n    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = AveragePooling2D(pool_size=(2,2))(d)\n    block_new = d\n    \n    # skip the input, 1x1 and activation for the old model\n    for i in range(n_input_layers, len(old_model.layers)):\n        d = old_model.layers[i](d)\n    model1 = Model(in_image, d)\n    \n    model1.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n    \n    downsample = AveragePooling2D(pool_size=(2,2))(in_image)\n    \n    block_old = old_model.layers[1](downsample)\n    block_old = old_model.layers[2](block_old)\n    d = WeightedSum()([block_old, block_new])\n    \n    for i in range(n_input_layers, len(old_model.layers)):\n        d = old_model.layers[i](d)\n        \n    model2 = Model(in_image, d)\n    \n    model2.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n    return [model1, model2]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define the discriminator models for each image resolution\ndef define_discriminator(n_blocks, input_shape=(4,4,3)):\n    init = RandomNormal(stddev=0.02)\n    const = max_norm(1.0)\n    model_list = list()\n    in_image = Input(shape=input_shape)\n    \n    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = MinibatchStdev()(d)\n    \n    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    \n    d = Flatten()(d)\n    out_class = Dense(1)(d)\n    \n    model = Model(in_image, out_class)\n    model.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n    model_list.append([model, model])\n    \n    for i in range(1, n_blocks):\n        old_model = model_list[i - 1][0]\n        models = add_discriminator_block(old_model)\n        model_list.append(models)\n        \n    return model_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define the discriminator models for each image resolution\ndef define_discriminator(n_blocks, input_shape=(4,4,3)):\n    init = RandomNormal(stddev=0.02)\n    const = max_norm(1.0)\n    model_list = list()\n    in_image = Input(shape=input_shape)\n    \n    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = MinibatchStdev()(d)\n    \n    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    \n    d = Flatten()(d)\n    out_class = Dense(1)(d)\n    \n    model = Model(in_image, out_class)\n    model.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n    model_list.append([model, model])\n    \n    for i in range(1, n_blocks):\n        old_model = model_list[i - 1][0]\n        models = add_discriminator_block(old_model)\n        model_list.append(models)\n        \n    return model_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define composite models for training generators via discriminators\n\ndef define_composite(discriminators, generators):\n    model_list = list()\n    # create composite models\n    for i in range(len(discriminators)):\n        g_models, d_models = generators[i], discriminators[i]\n        # straight-through model\n        d_models[0].trainable = False\n        model1 = Sequential()\n        model1.add(g_models[0])\n        model1.add(d_models[0])\n        model1.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n        # fade-in model\n        d_models[1].trainable = False\n        model2 = Sequential()\n        model2.add(g_models[1])\n        model2.add(d_models[1])\n        model2.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n        # store\n        model_list.append([model1, model2])\n    return model_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train a generator and discriminator\ndef train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n    bat_per_epo = int(dataset.shape[0] / n_batch)\n    n_steps = bat_per_epo * n_epochs\n    half_batch = int(n_batch / 2)\n    \n    for i in range(n_steps):\n        # update alpha for all WeightedSum layers when fading in new blocks\n        if fadein:\n            update_fadein([g_model, d_model, gan_model], i, n_steps)\n        # prepare real and fake samples\n        X_real, y_real = generate_real_samples(dataset, half_batch)\n        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n        \n        # update discriminator model\n        d_loss1 = d_model.train_on_batch(X_real, y_real)\n        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n        \n        # update the generator via the discriminator's error\n        z_input = generate_latent_points(latent_dim, n_batch)\n        y_real2 = ones((n_batch, 1))\n        g_loss = gan_model.train_on_batch(z_input, y_real2)\n        \n        # summarize loss on this batch\n        print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# generate samples and save as a plot and save the model\ndef summarize_performance(status, g_model, latent_dim, n_samples=25):\n    gen_shape = g_model.output_shape\n    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n    \n    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n    X = (X - X.min()) / (X.max() - X.min())\n    \n    square = int(sqrt(n_samples))\n    for i in range(n_samples):\n        pyplot.subplot(square, square, 1 + i)\n        pyplot.axis('off')\n        pyplot.imshow(X[i])\n        \n    # save plot to file\n    filename1 = 'plot_%s.png' % (name)\n    pyplot.savefig(filename1)\n    pyplot.close()\n    \n    filename2 = 'model_%s.h5' % (name)\n    g_model.save(filename2)\n    print('>Saved: %s and %s' % (filename1, filename2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# number of growth phases where 6 blocks == [4, 8, 16, 32, 64, 128]\nn_blocks = 6\nlatent_dim = 100\n\nd_models = define_discriminator(n_blocks)\ng_models = define_generator(latent_dim, n_blocks)\ngan_models = define_composite(d_models, g_models)\n\ndataset = load_real_samples('img_align_celeba_128.npz')\nprint('Loaded', dataset.shape)\n\nn_batch = [16, 16, 16, 8, 4, 4]\nn_epochs = [5, 8, 8, 10, 10, 10]\n\ntrain(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch)\n\n# Generate images from final (highest-res) generator\nfrom numpy.random import randn\nimport matplotlib.pyplot as plt\n\n# Get last generator model (128x128)\nfinal_generator = g_models[-1][-1]\n\n# Generate latent points\nlatent_points = randn(100 * 16).reshape(16, 100)\n\n# Generate fake images\nfake_images = final_generator.predict(latent_points)\n\n# Plot generated images\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    plt.axis('off')\n    img = (fake_images[i] + 1) / 2.0  # scale from [-1,1] to [0,1]\n    plt.imshow(img)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n    gen_shape = g_normal.output_shape\n    scaled_data = scale_dataset(dataset, gen_shape[1:])\n    print('Scaled Data', scaled_data.shape)\n\n    # train normal or straight-through models\n    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0])\n    summarize_performance('tuned', g_normal, latent_dim)\n    \n    # process each level of growth\n    for i in range(1, len(g_models)):\n        # retrieve models for this level of growth\n        [g_normal, g_fadein] = g_models[i]\n        [d_normal, d_fadein] = d_models[i]\n        [gan_normal, gan_fadein] = gan_models[i]\n        \n        # scale dataset to appropriate size\n        gen_shape = g_normal.output_shape\n        scaled_data = scale_dataset(dataset, gen_shape[1:])\n        print('Scaled Data', scaled_data.shape)\n        \n        # train fade-in models for next level of growth\n        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n        summarize_performance('faded', g_fadein, latent_dim)\n        \n        # train normal or straight-through models\n        train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n        summarize_performance('tuned', g_normal, latent_dim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# Step 1: Imports\n# -------------------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.random import randn\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\n\n# -------------------------------\n# Step 2: Define PixelNormalization (custom layer)\n# -------------------------------\nclass PixelNormalization(Layer):\n    def __init__(self, **kwargs):\n        super(PixelNormalization, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        # Normalize each pixel across channels\n        return inputs / tf.sqrt(tf.reduce_mean(tf.square(inputs), axis=-1, keepdims=True) + 1e-8)\n\n    def get_config(self):\n        config = super().get_config()\n        return config\n\n# -------------------------------\n# Step 3: Load Generator Model\n# -------------------------------\n# Make sure your .h5 file is uploaded in the Kaggle notebook directory\ngenerator = load_model('/kaggle/working/model_064x064-tuned.h5', custom_objects={'PixelNormalization': PixelNormalization})\n\n# -------------------------------\n# Step 4: Generate Latent Vectors\n# -------------------------------\nlatent_dim = 100      # Change this if your GAN was trained with a different latent size\nn_samples = 16        # Number of images to generate\n\nlatent_points = randn(n_samples * latent_dim).reshape(n_samples, latent_dim)\n\n# -------------------------------\n# Step 5: Generate Fake Images\n# -------------------------------\nfake_images = generator.predict(latent_points)\n\n# -------------------------------\n# Step 6: Plot the Generated Images\n# -------------------------------\nplt.figure(figsize=(8, 8))\nfor i in range(n_samples):\n    plt.subplot(4, 4, i + 1)\n    plt.axis('off')\n\n    # Scale from [-1, 1] to [0, 1]\n    img = (fake_images[i] + 1) / 2.0\n\n    # Grayscale or RGB support\n    if img.shape[-1] == 1:\n        img = img.squeeze()\n        plt.imshow(img, cmap='gray')\n    else:\n        plt.imshow(img)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}